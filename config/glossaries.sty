\newcommand{\newglossaryentryw}[3]{
    \newglossaryentry{#1}{
        name=#2,
        description={#3},
        first={#3 (#2)},
    }
}

\newglossaryentryw{NLP}{NLP}{\textit{natural language processing}}

\newglossaryentryw{SRL}{SRL}{\textit{semantic role labeling}}

\newglossaryentryw{AMR}{AMR}{\textit{abstract meaning representation}}

\newglossaryentryw{MBSE}{MBSE}{\textit{Maximum Bayes Smatch Ensemble Distillation for AMR Parsing}}

\newglossaryentryw{AMRBART}{AMRBART}{\textit{Graph Pre-training for AMR Parsing and Generation}}

\newglossaryentryw{stog}{stog}{\textit{AMR Parsing as Sequence-to-Graph Transduction}}

\newglossaryentryw{XL-AMR}{AMR}{\textit{Cross-lingual AMR}}

\newglossaryentryw{SMATCH}{SMATCH}{\textit{Evaluation Metric for Semantic Feature Structures}}

\newglossaryentryw{TLP}{TLP}{\textit{The Little Prince}}

\newglossaryentryw{BioAMR}{Bio}{\textit{Bio AMR}}

\newglossaryentryw{BART}{BART}{\textit{Denoising Sequence-to-Sequence Pre-training for Natural Language Generation, Translation, and Comprehension}}

\newglossaryentryw{PALM}{PALM}{\textit{Pre-training an Autoencoding\&Autoregressive Language Model for Context-conditioned Generation}}

\newglossaryentryw{BERT}{BERT}{\textit{Bidirectional Encoder Representations from Transformers}}

\newglossaryentryw{MASS}{MASS}{\textit{Masked Sequence to Sequence Pre-training for Language Generation}}

\newglossaryentryw{seq2seq}{seq2seq}{\textit{sequence-to-sequence}}
