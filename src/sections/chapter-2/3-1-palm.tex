\subsection{\Glsfirst{PALM}}

Self-supervised pre-training telah mencapai kesuksesan besar dalam natural language understanding (Devlin, Jacob, 2017).
Berbeda dengan pemahaman bahasa, language generation bertujuan untuk menghasilkan kalimat natural language  seperti neural machine translation (Vaswani, 2017).
Banyak dari language generation task yang membutuhkan model untuk membaca dan memahami dokumen yang diberikan, berdasar output teks yang dihasilkan.
Model bahasa yang kerap digunakan adalah \gls{PALM} untuk menghasilkan teks berbasis komprehensi membaca dari konteks tekstual.

\gls{PALM} secara spesifik didesain untuk melakukan pretrain dari backbone model pada corpus besar yang tidak berlabel untuk fine-tuning pada generation task yang berbasis komprehensif seperti generative question answering model.
Pada generative QA< model QA diminta untuk menghasilkan jawaban abstraksi dalam natural language terhadap pertanyaan yang diberikan dengan membaca dan memahami kalimat kontekstual.
Hasil jawaban abstraktif merupakan suatu manipulasi token dalam kalimat.
Jawaban abstraktif ini merefleksikan pemahaman terhadap kalimat dan pertanyaan, dan dapat memasukkan konten dari kalimat sehingga kalimat yang dihasilkan dapat terbentuk dengan baik.
Untuk menjawab comprehension-based generation seperti pada generative QA, \gls{PALM} menggunakan pre-training objective yang berhubungan erat dengan downstream task.
Secara spesifik, yang membedakan \gls{PALM} dengan metode generative pre-training yang ada saat ini adalah \gls{PALM} tidak hanya melakukan metode auto encoding atau autoregressive.
\gls{PALM} mengkombinasikan auto encoding dan autoregression dalam satu framework tunggal.
Terlebih lagi, \gls{PALM} memiliki mekanisme built-in pre-training untuk menghasilkan teks koheren dari konteks yang diberikan.

Dengan desain ini, \gls{PALM} melampaui metode language generation dengan atau tanpa pre-training.
\gls{PALM} memberikan hasil empiris yang baik terhadap berbagai variasi context-aware generation tasks, seperti Rouge-L pada MARCO Natural Language Generation dengan benchmark hingga 0.498 (Rank 1 on the leaderboard 1) dan Gigaword summarization hingga 36.75.
