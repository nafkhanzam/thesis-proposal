\section{Analisis Masalah}

Pelatihan pembelajaran mesin untuk \textit{task} \amrparsing{} memerlukan dataset \textit{training} pasangan kalimat dan graf \gls{AMR}-nya.
Dataset AMR 3.0 menyediakan 59,255 pasangan kalimat berbahasa Inggris dan graf \gls{AMR}.
Namun terdapat keterbatasan dataset untuk \textit{task} \amrparsing{} dari bahasa selain Bahasa Inggris.
Dalam penelitian \textcite{blloshmi2020}, setidaknya diperlukan dataset yang berkualitas silver untuk data latih dan gold untuk melakukan evaluasi model.
Misal untuk membangun model untuk \amrparsing{} dari kalimat berbahasa Indonesia menjadi graf \gls{AMR}, diperlukan dataset pasangan kalimat berbahasa Indonesia dengan graf \gls{AMR}-nya yang berkualitas gold dan silver.

Saat ini terdapat dataset berkualitas silver dan gold untuk kalimat berbahasa Indonesia dari Dataset AMR 2.0 dan korpus paralel BPPT-PANL \citek{putra2022}.
\cref{tab:1-dataset-putra} menunjukkan dataset yang dibangun oleh \textcite{putra2022}.
Dataset Silver Trans merupakan hasil translasi dari kalimat berbahasa Inggris yang berkualitas gold.
Dataset Silver Par merupakan hasil \textit{parsing} kalimat berbahasa Inggris yang berkualitas gold menjadi graf \gls{AMR}.

\tabl{1-dataset-putra}
  {sections/chapter-3/1-dataset-putra.csv}
  {Statistik dataset berkualitas gold dan silver yang dibangun oleh \textcite{putra2022}.}

\textcite{putra2022} telah membangun sebuah model \gls{AMR} \textit{Parser} Lintas Bahasa untuk Bahasa Indonesia dengan skor \gls{SMATCH} 51.0.
Model tersebut dibangun dengan \mwordem{} mT5 yang merupakan sebuah \glsfirst{PLM}.
Namun dengan baseline dari \textit{pipline translate-and-parse} yang memiliki skor \gls{SMATCH} 62.5, model tersebut masih belum dapat melampaui kinerja baseline.
\textcite{putra2022} menggunakan teknik Sequence-to-Graph Transduction \citek{zhang2019} yang bukan lagi \textit{state of the art} \amrparsing{} saat ini.
\textcite{bai2022} menyebutkan bahwa \gls{PLM} umumnya dilatih pada data tekstual, sehingga tidak optimal untuk melakukan generasi data terstruktur seperti \gls{AMR}.
Hasil evaluasi yang buruk juga dimungkinkan disebabkan oleh kualitas data latih yang buruk.
\textcite{lee2022} menyebutkan bahwa kenaikan kinerja dari \amrparsing{} dari penelitian-penelitian sebelumnya tidak lagi meningkat secara signifikan.
Ini dikarenakan efek dari self-learning dan augmentasi silver data mulai berkurang.
