\section{Rancangan Solusi}

% General Dataset Construction
Pada masalah kurangnya jumlah dataset yang digunakan sebagai data latih model, dibangun kumpulan dataset silver untuk pelatihan model \amrparsing{} lintas bahasa.
Diagram alur keseluruhan proses konstruksi dataset gold dan silver dapat dilihat pada \cref{fig:3-dataset-construction}.
Alur proses konstruksi dataset berkualitas silver mengikuti framework augmentasi data oleh \textcite{lee2022}.

\fig[1]{3-dataset-construction}
  {sections/chapter-3/3-dataset-construction.png}
  {Diagram alur untuk konstruksi dataset gold dan silver dari korpus paralel dan dataset AMR.}

% Dataset Silver Parallel Corpora
Korpus paralel PANL-BPPT dan IWSLT2017 digunakan sebagai dataset pasangan kalimat Bahasa Inggris dan Bahasa Indonesia.
Kalimat berbahasa Inggris dari korpus paralel diubah menjadi graf \AMR{}.
Model \amrparsing{} yang digunakan adalah teknik \ti{ensembling} dari 5 model \sota{} \citek{lee2022}.
Hasil graf \AMR{} yang dihasilkan akan digunakan sebagai dataset latih berkualitas silver.

% Dataset Silver AMR 3.0
Dataset \AMR{} berkualitas gold yang digunakan adalah Dataset AMR 3.0 (LDC2020T02).
Augmentasi data untuk konstruksi dataset berkualitas silver mengambil bagian Train dan Dev \ti{split} dari AMR 3.0.
Kalimat berbahasa Inggris dari dataset \AMR{} tersebut diubah menjadi kalimat berbahasa Indonesia dengan menggunakan mesin translasi.
Model mesin translasi yang digunakan adalah model {OPUS-MT} \citek{tiedemann2020}.
Graf \AMR{} berkualitas gold juga dilakukan \ti{parsing} menjadi kalimat berbahasa Inggris (AMR-to-text) untuk menambah jumlah variasi pasangan dataset.
Model AMR-to-text yang digunakan adalah \gls{AMRBART}.
Kalimat berbahasa Inggris hasil \ti{parsing} tersebut juga diubah menjadi kalimat berbahasa Indonesia dengan menggunakan mesin translasi.
Maka akan terdapat dua pasangan kalimat berbahasa Inggris dan Indonesia untuk satu buah graf \AMR{}.
Dua pasangan tersebut dilakukan \ti{cross join} untuk menghasilkan empat pasang data latih berkualitas silver.

% Quality measurement and filtration.
Kumpulan semua dataset silver tersebut kemudian dilakukan filtrasi dengan algoritma 1-NN dengan \cossim{} sebagai fungsi jarak antar representasi kalimatnya.
Hasil filtrasi yang dihasilkan akan digunakan sebagai dataset latih.
Dataset latih tersebut juga dihitung kualitasnya menggunakan rata-rata \cossim{}.

% Dataset Gold
Augmentasi data untuk konstruksi dataset berkualitas gold mengambil bagian Test \ti{split} dari AMR 3.0.
Bagian kalimat berbahasa Inggris dari Test \ti{split} ditranslasi menjadi Bahasa Indonesia oleh ahli.
Hasil kalimat berbahasa Indonesia tersebut berkualitas gold dan digunakan sebagai dataset test.

\newcommand\graphMasked{\codesm{\textcolor[rgb]{0,.33,0}{<g>$g_1$,..[mask]..,$g_m$</g>}}}
\newcommand\graphBarMasked{\codesm{\textcolor[rgb]{0,.33,0}{<g>[mask]</g>}}}
\newcommand\idTagged[1]{\codesm{\textcolor{purple}{<id>#1</id>}}}
\newcommand\enTagged[1]{\codesm{\textcolor{blue}{<en>#1</en>}}}
\newcommand\sTagged[1]{\codesm{\textcolor{purple}{<s>#1</s>}}}

% Training Techniques
Skema pelatihan yang digunakan hanya untuk yang melakukan \amrparsing{} dengan menggunakan skema \ti{bilingual}.
Ilustrasi pelatihan dengan skema \ti{bilingual} dapat dilihat pada \cref{fig:3-bilingual-training-schema}
Pelatihan dicoba dengan konfigurasi dengan dan tanpa \ti{concatenating}.
Pada konfigurasi tanpa \ti{concatenating} tetap mengikuti teknik pelatihan sebelumnya yang dapat dilihat pada \cref{tab:3-pt-ft-strategies}.
Sedangkan pada konfigurasi dengan \ti{concatenating}, diperlukan sedikit modifikasi untuk melakukan \pretraining{} graf pada teknik \gls{AMRBART}.
Token \code{<s>} yang digunakan pada \gls{AMRBART} diganti menjadi kode bahasa yang digunakan.
Bahasa Indonesia ditandai dengan token \code{<id>} dan Bahasa Inggris ditandai dengan token \code{<en>}.
Kalimat berbahasa Indonesia dan Inggris dilinearisasi secara sejajar sebagai input \pretraining{} maupun \finetuning{}.
Strategi \pretraining{} dan \finetuning{} untuk pelatihan graf model \amrparsing{} lintas bahasa tersebut dapat dilihat pada \cref{tab:3-pt-ft-strategies-with-concat}.
Output dari pelatihan tersebut merupakan graf \AMR{} yang dilinearisasi, yaitu \code{<g>$g_1$,..,$g_m$</g>}.
Linearisasi graf menggunakan algoritma \gls{DFS} \citek{bevilacqua2021}.

\fig[0.6]{3-bilingual-training-schema}
  {sections/chapter-3/3-bilingual-training-schema.png}
  {Pelatihan dengan skema \ti{bilingual}.}

\begin{filecontents*}{3-pt-ft-strategies.csv}
Phase,Task,Input
PT,\code{$\bar{t}\hat{g}2g$},\makecell[cl]{\sTagged{[mask]}\graphMasked{}}
,\code{$t\hat{g}2g$},\makecell[cl]{\sTagged{$a_1$,..,$a_n$}\graphMasked{}}
,\code{$\hat{t}\hat{g}2g$},\makecell[cl]{\sTagged{$a_1$,..[mask]..,$a_n$}\graphMasked{}}
FT,\code{$t\bar{g}2g$},\makecell[cl]{\sTagged{$a_1$,..,$a_n$}\graphMasked{}}
\end{filecontents*}
\tabl{3-pt-ft-strategies}
  {3-pt-ft-strategies.csv}
  {
    Strategi \pretraining{} (PT) dan \finetuning{} (FT) untuk pelatihan graf model \amrparsing{} lintas bahasa pada skema pelatihan \ti{bilingual}.
    \code{$t/g$} merupakan teks/graf \ti{original}.
    \code{$\hat{t}/\hat{g}$} merupakan teks/graf yang \ti{noisy} (hasil \denoising{}).
    \code{$\bar{t}/\bar{g}$} merupakan teks/graf yang hilang.
    Semua output dari pelatihan ini adalah bentuk graf yang utuh.
  }

\begin{filecontents*}{3-pt-ft-strategies-with-concat.csv}
Phase,Task,Input
PT,\code{$\bar{t}_{_{ID}}\bar{t}{_{_{EN}}}\hat{g}2g$},\makecell[cl]{\idTagged{[mask]}\enTagged{[mask]}\graphMasked{}}
,\code{$t_{_{ID}}\bar{t}{_{_{EN}}}\hat{g}2g$},\makecell[cl]{\idTagged{$a_1$,..,$a_{n_1}$}\enTagged{[mask]}\graphMasked{}}
,\code{$\bar{t}{_{_{ID}}}t_{_{EN}}\hat{g}2g$},\makecell[cl]{\idTagged{[mask]}\enTagged{$b_1$,..,$b_{n_2}$}\graphMasked{}}
,\code{$t_{_{ID}}t_{_{EN}}\hat{g}2g$},\makecell[cl]{\idTagged{$a_1$,..,$a_{n_1}$}\enTagged{$b_1$,..,$b_{n_2}$}\graphMasked{}}
,\code{$t_{_{ID}}\hat{t}{_{_{EN}}}\hat{g}2g$},\makecell[cl]{\idTagged{$a_1$,..,$a_{n_1}$}\enTagged{$b_1$,..[mask]..,$b_{n_2}$}\graphMasked{}}
,\code{$\hat{t}{_{_{ID}}}t_{_{EN}}\hat{g}2g$},\makecell[cl]{\idTagged{$a_1$,..[mask]..,$a_{n_1}$}\enTagged{$b_1$,..,$b_{n_2}$}\graphMasked{}}
,\code{$\hat{t}{_{_{ID}}}\hat{t}{_{_{EN}}}\hat{g}2g$},\makecell[cl]{\idTagged{$a_1$,..[mask]..,$a_{n_1}$}\enTagged{$b_1$,..[mask]..,$b_{n_2}$}\graphMasked{}}
FT,\code{$t_{_{ID}}\bar{t}{_{_{EN}}}\bar{g}{}2g$},\makecell[cl]{\idTagged{$a_1$,..,$a_{n_1}$}\enTagged{[mask]}\graphBarMasked{}}
,\code{$\bar{t}{_{_{ID}}}t_{_{EN}}\bar{g}{}2g$},\makecell[cl]{\idTagged{[mask]}\enTagged{$b_1$,..,$b_{n_2}$}\graphBarMasked{}}
\end{filecontents*}
\tabl{3-pt-ft-strategies-with-concat}
  {3-pt-ft-strategies-with-concat.csv}
  {
    Strategi \pretraining{} (PT) dan \finetuning{} (FT) untuk pelatihan graf model \amrparsing{} lintas bahasa pada skema pelatihan \ti{bilingual} dengan konfigurasi \ti{concatenating}.
    \code{$t/g$} merupakan teks/graf \ti{original}.
    \code{$\hat{t}/\hat{g}$} merupakan teks/graf yang \ti{noisy} (hasil \denoising{}).
    \code{$\bar{t}/\bar{g}$} merupakan teks/graf yang hilang.
    Semua output dari pelatihan ini adalah bentuk graf yang utuh.
  }

Pembangunan data latih silver ketika \pretraining{} dilakukan \ti{masking} secara dinamis ketika melakukan training \citek{bai2022}.
Fungsi \ti{noising} dilakukan secara acak untuk melakukan \ti{masking} sebuah subgraf, 15\% bagian untuk \ti{masking} simpul (konsep), dan/atau 15\% untuk \ti{masking} sisi (relasi).
Sebuah subgraf minimal memiliki satu simpul dan satu sisi.
Setiap jenis \ti{noising} tersebut memiliki kemungkinan yang bertambah setiap \ti{step} pelatihan.
Nilai kemungkinan tersebut dapat dilihat pada \cref{eq:masking-probability}.
Nilai $p$ merupakan kemungkinan dilakukan \ti{noising}.
Nilai $t$ merupakan iterasi pelatihan dan $T$ merupakan iterasi maksimal.

\eq{masking-probability}{p = 0.1 + 0.75 \times t/T}

Pelatihan \amrparsing{} akan dicoba pada beberapa \multil{} model.
Model-model yang akan dicoba adalah mBART, mT5, IndoBART, dan IndoT5.
Eksperimen \amrparsing{} juga akan dicoba dengan teknik \AMR{} ensembling \citek{hoang2021} dari hasil semua model-model tersebut.

% Evaluation
Evaluasi dilakukan secara kuantitatif dan kualitatif.
Metrik evaluasi yang digunakan untuk evaluasi kuantitatif adalah \SMATCH{}.
Evaluasi tersebut dilakukan dengan menghitung kemiripan graf \AMR{} hasil prediksi dan graf \AMR{} asli dari dataset test.
Metode kualitatif yang digunakan adalah evaluasi \transdiver{}.

% Baseline Evaluation
Pendekatan \ti{translate-and-parse} \citek{uhrig2021} digunakan sebagai baseline pada penelitian ini.
Model mesin translasi yang digunakan adalah {OPUS-MT} dan model \amrparsing{} yang digunakan adalah \gls{AMRBART}.
Tahapan yang dilakukan adalah melakukan translasi dari kalimat berbahasa Indonesia menjadi Bahasa Inggris, lalu dilakukan \amrparsing{} menjadi graf \AMR{}.
